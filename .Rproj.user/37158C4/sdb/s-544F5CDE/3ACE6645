{
    "contents" : "#' Perform k-fold cross validation\n#' \n#' \n#' @param dset label ranking dataset\n#' @param k the number of nearest neighbors to search. The default value is set to 10\n#' @param nFolds the number of folds for the cross validation\n#' @param nRuns the number of runs for the cross validation\n#' @param alpha the default value is set to 0.05\n#' @return ???\n#' @examples\n#' # perform the 10 runs of 10-folds cross validation on the Iris dataset\n#' dset = data(data.iris)\n#' cv.knn(dset, k=15, nFolds=10, nRuns=10, alpha=0.05)\n#' @export\n\ncv.knn <- function(dset, k=10, nFolds=10, nRuns=10, alpha=0.05) {\nlibrary(FNN)\n#source(\"libs/plmm.R\")\n#source(\"libs/pl2.R\")\n#source(\"libs/lib_data.R\")\n#source(\"libs/lib_eval.R\")\n#source(\"libs/lib_knn.R\")\n#source(\"libs/lib_pmr.R\")\n#File <- \"dataset/wine\"\n#dset <- read.table(File, sep=\",\")\nK <- k\nnbFold <- nFolds\nnbRuns <- nRuns\nnbRows <- dim(dset)[1] # number of instances (rows)\nnbCols <- dim(dset)[2] # number of attributes including label ranking (columns)\n\n# count the number of labels\ns=dset[1,nbCols] # The string to search in\ns=sapply(s,as.character)\np <- \"L\" # The character to search for\ns2 <- gsub(p,\"\",s)\nnbLabel <- numOcc <- nchar(s) - nchar(s2)\n\npl_h <- c(0) # number of times the 2-vase model is selected\nnbClassify <- 0 # number of all test rows that have been classified\nh <- 0 # logical number of loglikelihood ratio test, h=1: 2-vase model is preferred, h=0: 1-vase model is preferred \nnb <- 0\n\npl1_ta <- c(0) # number of Kendall's tau for 1-vase model\npl2_ta <- c(0) # number of Kendall's tau for 2-vase model\npl3_ta <- c(0) # number of Kendall's tau for mix model (1-vase and 2-vase model)\n\npl1_sp <- c(0) # number of Spearman rank correlation for 1-vase model\npl2_sp <- c(0) # number of Spearman rank correlation for 2-vase model\npl3_sp <- c(0) # number of Spearman rank correlation mix model (1-vase and 2-vase model)\n\n# Average Kendall's tau for each run in 10-fold cross-validation\npl1_ta_cv_avg <- c(0) \npl2_ta_cv_avg <- c(0)\npl3_ta_cv_avg <- c(0)\n\n# Average Spearman rank correlation for each run in k-fold cross-validation\npl1_sp_cv_avg <- c(0)\npl2_sp_cv_avg <- c(0)\npl3_sp_cv_avg <- c(0)\n\n# Average likelihood ratio test\npl1_ll_avg <- c(0)\npl2_ll_avg <- c(0)\npl3_ll_avg <- c(0)\n\ndset <- data.frame(scale(dset[,1:dim(dset)[2]-1]), Ranks=dset[,dim(dset)[2]]) # Standardized the features\ndset <- dset[order(dset$Ranks),] # Sort dataset according to their class\ndset <- sortRandom(dset) # Sort dataset according random random column\ndset <- dset[2:dim(dset)[2]]\nfold <- cv.getFolds(nbRows, nbFold) # get fold index\n\n# run cross validation\nfor (run in 1:nbRuns) {\n  \n  message(\"Evaluating fold...\", run)\n  \n  # Test and train dataset\n  testRows <- c(fold$TestS[run]:fold$TestE[run])\n  trainRows <- c(fold$TrainS1[run]:fold$TrainE1[run], fold$TrainS2[run]:fold$TrainE2[run])\n  testFeatures <-  dset[testRows, 1:(dim(dset)[2]-1)]\n  trainFeatures <- dset[trainRows, 1:(dim(dset)[2]-1)] \n  testClasses <- dset[testRows, dim(dset)[2]]\n  trainClasses <- dset[trainRows, dim(dset)[2]]\n  \n  # actual rank, used to compare with the estimated rank\n  actual_rank <- gsub('L','',testClasses)\n  actual_rank <- gsub('>',' ',actual_rank)\n  actual_rank <- data.frame(strsplit(actual_rank,' '))\n  colnames(actual_rank) <- c(1:dim(actual_rank)[2])\n  actual_rank <- t(actual_rank) \n  class(actual_rank) = \"numeric\"\n  \n  # Search and find the ranks according to nearest neighbors\n  instance <- get.knnx(trainFeatures, testFeatures, K, algo=\"kd_tree\")\n  ranks <- knn.getRanks(trainClasses, instance$nn.index)\n  \n  #\n  # Loop through all ranks in the test dataset and estimate the parameters\n  #\n  for (nbTest in 1:dim(ranks)[2]) {\n    nbClassify=nbClassify+1\n    \n    #\n    # Modify the ranks to match with the data structure requied in pl.R and pl.extend.R\n    #\n    temp <- gsub('L','',ranks[,nbTest])\n    temp <- gsub('>',' ',temp)\n    test <- data.frame(strsplit(temp,' '))\n    colnames(test) <- c(1:dim(test)[2])\n    test <- t(test) # all ranks in each row of test set\n    class(test) = \"numeric\"\n    #data.rank.plmm <- formDsetNascar(test)\n    \n    # initial result variables\n    if (nbTest==1) {\n      pl1_para <- matrix(0,dim(ranks)[2], dim(test)[2]) # estimate parameters\n      pl2_para <- pl1_para # estimate parameters\n      pl1_rank <- pl1_para # rank order of 1-vase model\n      pl2_rank <- pl1_para # rank order of 2-vase model\n      pl3_rank <- pl1_para # rank order mixed between 1-vase and selected 2-vase model\n      pl1_ll <- c(0)\n      pl2_ll <- c(0)\n      pl3_ll <- c(0)\n    }\n    \n    skipDset <- FALSE \n    skip2vase <- FALSE\n    # Check if the object is always ranked first or last\n    # we then don't apply the algorithm on this object/dataset\n    #if (check_rank) {\n    #  r <- checkRank(test)\n    #  if ( r$rank_first || r$rank_last ) \n    #  {skipDset = TRUE}\n    # }\n    \n    # Skip 2vase-model\n    #if (dim(data.rank)[1]==1) {\n    #  skip2vase <- TRUE \n    #}\n    \n    # Check if the optimization is not successful\n    # we don't account this in the calculation\n    #tmp1 <- try(pl(data.rank), TRUE)\n    \n    # plmm\n    tmp1 <- est.PL.MM(test)\n    if (is.nan(tmp1$loglikelihood)) { \n      pl1_ll[nbTest] <- 3333 \n      message(\"Nan produced\")\n      skip2vase <- TRUE\n    } else {\n      pl1_ll[nbTest] <- tmp1$loglikelihood\n    }\n    pl1_rank[nbTest,] <- order(tmp1$para, decreasing = TRUE) # rank index\n    \n    # pl\n    #pl1_rank[nbTest,] <- order(tmp1$par, decreasing = TRUE) # rank index\n    #pl1_ll[nbTest] <- -tmp1$value\n    #browser()\n    # pl2\n    if (skip2vase) {\n      pl2_rank[nbTest,] <- pl1_rank[nbTest,]\n      pl2_ll[nbTest] <- pl1_ll[nbTest]\n    } else {\n      tmp2 <- getLL(test) # getLL has try() to check error\n      pl2_ll[nbTest] <- tmp2$loglikelihood # loglikelihood\n      tmp3 <- getParaV2(tmp2$para, tmp2$L) # parameters and cutpoint (L)\n      pl2_rank[nbTest,] <- tmp3$rank\n    }\n    \n    ###########################\n    # loglikelihood ratio test\n    ###########################\n    h <- eval.LRatioTest(pl2_ll[nbTest], pl1_ll[nbTest], nbLabel, alpha) # degree of freedom = nbLabel-1\n    if (h == 1) { # 2-vase model is selected\n      pl3_rank[nbTest,] <- pl2_rank[nbTest,]\n      pl_h[nbClassify] <- 1\n      pl3_ll[nbTest] <- pl2_ll[nbTest]\n    } else { # 1-vase model is selected\n      pl3_rank[nbTest,] <- pl1_rank[nbTest,]\n      pl_h[nbClassify] <- 0\n      pl3_ll[nbTest] <- pl1_ll[nbTest]\n    }\n    \n    #########################\n    # Evaulations\n    ######################### \n    message(nbClassify,\"/\",nbRows)\n    # Construct a matrix\n    t1 <- data.frame(as.numeric(actual_rank[nbTest,]), pl1_rank[nbTest,])\n    t2 <- data.frame(as.numeric(actual_rank[nbTest,]), pl2_rank[nbTest,])\n    t3 <- data.frame(as.numeric(actual_rank[nbTest,]), pl3_rank[nbTest,])\n    \n    # Kendall's tau\n    pl1_ta[nbTest] <- eval.KendallTau(t1)\n    pl2_ta[nbTest] <- eval.KendallTau(t2)\n    pl3_ta[nbTest] <- eval.KendallTau(t3) \n    \n    # Spearman rank correlation\n    pl1_sp[nbTest]  <- eval.SpearmanRho(t1)\n    pl2_sp[nbTest]  <- eval.SpearmanRho(t2)\n    pl3_sp[nbTest]  <- eval.SpearmanRho(t3)\n    \n  }\n  \n  nb <- nb+1\n  pl1_ta_cv_avg[nb] <- mean(pl1_ta[which(pl1_ta!=3333)])\n  pl2_ta_cv_avg[nb] <- mean(pl2_ta[which(pl2_ta!=3333)])\n  pl3_ta_cv_avg[nb] <- mean(pl3_ta[which(pl3_ta!=3333)])\n  pl1_sp_cv_avg[nb] <- mean(pl1_sp[which(pl1_sp!=3333)])\n  pl2_sp_cv_avg[nb] <- mean(pl2_sp[which(pl2_sp!=3333)])\n  pl3_sp_cv_avg[nb] <- mean(pl3_sp[which(pl3_sp!=3333)])\n  pl1_ll_avg[nb] <- mean(pl1_ll[which(pl1_ll!=3333)])\n  pl2_ll_avg[nb] <- mean(pl2_ll[which(pl2_ll!=3333)])\n  pl3_ll_avg[nb] <- mean(pl3_ll[which(pl3_ll!=3333)])\n  \n} #end cross validation\n\nresult <- list(\"pl1_ta\"=mean(pl1_ta_cv_avg[which(pl1_ta_cv_avg!=3333)]), \n               \"pl2_ta\"=mean(pl2_ta_cv_avg[which(pl2_ta_cv_avg!=3333)]), \n               \"pl3_ta\"=mean(pl3_ta_cv_avg[which(pl3_ta_cv_avg!=3333)]),\n               \"pl1_ta_cv\"=pl1_ta_cv_avg,\n               \"pl2_ta_cv\"=pl2_ta_cv_avg,\n               \"pl3_ta_cv\"=pl3_ta_cv_avg,\n               \"pl1_sp\"=mean(pl1_sp_cv_avg[which(pl1_sp_cv_avg!=3333)]), \n               \"pl2_sp\"=mean(pl2_sp_cv_avg[which(pl2_sp_cv_avg!=3333)]), \n               \"pl3_sp\"=mean(pl3_sp_cv_avg[which(pl3_sp_cv_avg!=3333)]),\n               \"pl1_sp_cv\"=pl1_sp_cv_avg,\n               \"pl2_sp_cv\"=pl2_sp_cv_avg,\n               \"pl3_sp_cv\"=pl3_sp_cv_avg,\n               \"pl1_ll\"=mean(pl1_ll_avg[which(pl1_ll_avg!=3333)]), \n               \"pl2_ll\"=mean(pl2_ll_avg[which(pl2_ll_avg!=3333)]), \n               \"pl3_ll\"=mean(pl3_ll_avg[which(pl3_ll_avg!=3333)]), \n               \"pl_h\"=pl_h)\n\n}\n\n#\n# sortRandom create a randomCol using for sorting the dataset\n# sort the dataset accoding to the randomCol \n# this gives cross validation randomness\n#\nsortRandom <- function(dset) {\n  \n  dsetRowNumber <- dim(dset)[1] # Total number of rows\n  set.seed(1)\n  randomCol <- runif(dsetRowNumber) # A random column\n  temp <- cbind(randomCol,dset)\n  dsetSorted <- temp[order(temp$randomCol),]\n  \n  return(dsetSorted)\n  \n}\n\n#\n# check is any object is always ranked first or last\n#\ncheckRank <- function(rank) {\n  rank_first = FALSE\n  rank_last = FALSE\n  ncols = dim(rank)[2]\n  \n  # always rank first\n  if ( length(unique(rank[,1])) == 1 )\n    rank_first = TRUE\n  \n  # always rank last\n  if ( length(unique(rank[,ncols])) == 1 )\n    rank_last = TRUE\n  \n  result <- list(\"rank_first\"=rank_first, \"rank_last\"=rank_last)\n}\n\n#\n# Find the switch point (L) that maximizes the likelihood\n#\n# input: \n# - dset\n# return: \n# - switch point\n# - loglikelihood\n# - parameters\ngetLL <- function(dset) {\n  \n  nitem <- dim(dset)[2]\n  ll <- c(0)\n  result.extend <- matrix(0,nitem-1,nitem*2)\n  \n  for (i in 1:(nitem-2)) {\n    tmp <- try(est.PL2.NR(dset, i),TRUE)\n    if ( inherits(tmp, \"try-error\") ) {\n      ll[i] <- -999999 # this won't be select\n    } else {\n      result.extend[i,] <- tmp$para\n      ll[i] <- tmp$loglikelihood\n    }\n  }\n  \n  L <- which.max(ll)\n  result <- list(\"L\"=L,\"loglikelihood\"=ll[L], \"para\"=result.extend[L,])\n  \n  return(result)\n  \n}\n\n#\n# getParaV2 get the most probable rank\n#\ngetParaV2 <- function(para, L) {\n  \n  labels <- length(para)/2\n  v_rank <- c(0)\n  v_para <- c(0)\n  v1 <- para[1:labels]/sum(para[1:labels])\n  r1 <- order(v1, decreasing = TRUE) # rank index\n  v2 <- para[(labels+1):(2*labels)]/sum(para[(labels+1):(2*labels)])\n  r2 <- order(v2, decreasing = TRUE) # rank index\n  \n  # skip V2 if V2 contains the same parameters/rank (e.g. 1 1 1)\n  if (all(r2==1)) {\n    v_rank <- r1\n    v_para <- v1\n  } else {\n    v_rank[1:L] <- r1[1:L]\n    v_para[1:L] <- v1[r1[1:L]]\n    v_rank[(L+1):labels] <- setdiff(r2,v_rank) \n    v_para[(L+1):labels] <- v2[v_rank[(L+1):labels]]\n  }\n  v_para = v_para/sum(v_para)\n  result <- list(\"para\"=v_para[order(v_rank)], \"rank\"=v_rank)\n  \n  return(result)\n}",
    "created" : 1407868074977.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1763063019",
    "id" : "3ACE6645",
    "lastKnownWriteTime" : 1407924603,
    "path" : "~/dropbox/thesis/codes/R/PLRank/R/cv.knn.R",
    "project_path" : "R/cv.knn.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}